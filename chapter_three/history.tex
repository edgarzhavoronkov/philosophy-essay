\subsection{Историческая справка}

Согласно \cite{omodeo2017martin}, еще в пятидесятых годах прошлого века Мартином Девисом(англ. Martin Davis) было представлено первое формальное доказательство, полученное автоматически -- доказательство того, что произведение двух четных чисел четно в арифметике Пресбургера. Спустя короткое время, уже в конце шестидесятых, начали появляться первые автоматические доказатели теорем, которые использовались для верификации программ, написанных на таких языках, как \textbf{Pascal}, \textbf{Ada} и \textbf{Java}.

Еще позже, в 1972 году, Робином Милнером(англ. Robin Milner) была создана система проверки доказательств \textbf{LCF}(Logic for Computable Functions), которая положила начало современным системам автоматического доказательства теорем, таким как \textbf{HOL} или \textbf{Coq}. На текущий момент, Coq является одним из самых популярных инструментов формальной верификации и автоматического доказательства теорем.

У доказателей теорем есть один недостаток, который заключается в том, что если некоторое утверждение \textbf{не} является теоремой в некоторой логике, то доказатель ничего не сможет вам об этом сказать. Иначе говоря, доказатели теорем годятся только в случае, если мы заведомо знаем, что наше утверждение является истинным и хотим получить формальное доказательство этого факта.

Для верификации конкурентных(многопоточных) программ широко используются другие методы, например проверка моделей. Их история начинается в восьмидесятых годах с работ Аллена Эмерсона и Эдмунда Кларка(англ. E. Allen Emerson и Edmund M. Clarke) о применении в этой области темпоральной логики, например -- \cite{Clarke:1981:DSS:648063.747438}. Важной особенностью именно этой работы было то, что их алгоритм был пригоден для работы с частичными спецификациями и мог приводить контрпримеры для свойств, которые не мог доказать.

Недостатком проверки моделей является следующий момент. Так как их применяют для анализа систем, которые находятся в некотором состоянии, то размер пространства состояний может экспоненциально зависеть от сложности программы. Следовательно задача анализа такой системы может быть затруднительна с вычислительной точки зрения. Для борьбы с этой проблемой зачастую используют всевозможные методы понижения размерности либо решают эту задачу приближенными методами.

Если оторваться от контекста индустрии разработки ПО, то принцип верификации был выдвинут еще в тридцатых годах. Студенты и преподаватели кафедры философии индуктивных наук Венского университета собирали семинар, более известный как Венский Кружок. Именно там под влиянием идей еще Эрнста Маха(нем. Ernst Mach), выдвинувшего мысль о том, что <<суждения, которые не могут быть ни проверены, ни отвергнуты не имеют отношения к науке>> -- цитата по \cite{wiki:mach} был сформулирован принцип верификационизма, утверждавший о том, что к реальному миру имеют отношения лишь те суждения, которые можно проверить экспериментом.
